{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Weights and Biases:\n",
      "w1_h1: 0.1992582667893168\n",
      "w1_h2: 0.19113010172187275\n",
      "w2_h1: 0.34851653357863355\n",
      "w2_h2: 0.28226020344374547\n",
      "w1_o1: -1.9914689533256722\n",
      "w1_o2: 1.8330932331690575\n",
      "b1_h: 1.335165335786316\n",
      "b2_h: 0.17260203443746525\n",
      "b1_o: -3.0701434055608114\n",
      "b2_o: 2.6156759959040747\n",
      "Final Outputs (a1_o, a2_o): 0.012308558812928694 0.9876794668658311\n",
      "Total Error: 5.357158909763266e-06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Inputs\n",
    "x1 = 0.05\n",
    "x2 = 0.10\n",
    "\n",
    "# Biases\n",
    "b1_h = 0.35\n",
    "b2_h = 0.35\n",
    "b1_o = 0.60\n",
    "b2_o = 0.60\n",
    "\n",
    "# Weights\n",
    "w1_h1 = 0.15\n",
    "w1_h2 = 0.20\n",
    "w2_h1 = 0.25\n",
    "w2_h2 = 0.30\n",
    "w1_o1 = 0.40\n",
    "w1_o2 = 0.45\n",
    "w2_o1 = 0.50\n",
    "w2_o2 = 0.55\n",
    "\n",
    "# Target values\n",
    "t1_o = 0.01\n",
    "t2_o = 0.99\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Number of iterations\n",
    "num_iterations = 10000\n",
    "\n",
    "# Training loop\n",
    "for iteration in range(num_iterations):\n",
    "    # Forward Pass\n",
    "    z1_h = (x1 * w1_h1) + (x2 * w2_h1) + b1_h\n",
    "    z2_h = (x1 * w1_h2) + (x2 * w2_h2) + b2_h\n",
    "    a1_h = sigmoid(z1_h)\n",
    "    a2_h = sigmoid(z2_h)\n",
    "    z1_o = (a1_h * w1_o1) + (a2_h * w2_o1) + b1_o\n",
    "    z2_o = (a1_h * w1_o2) + (a2_h * w2_o2) + b2_o\n",
    "    a1_o = sigmoid(z1_o)\n",
    "    a2_o = sigmoid(z2_o)\n",
    "\n",
    "    # Calculate the error\n",
    "    E1_o = 0.5 * (t1_o - a1_o)**2\n",
    "    E2_o = 0.5 * (t2_o - a2_o)**2\n",
    "\n",
    "    # Total error\n",
    "    total_error = E1_o + E2_o\n",
    "\n",
    "    # Backward Pass and Weight Updates\n",
    "    delta1_o = (a1_o - t1_o) * a1_o * (1 - a1_o)\n",
    "    delta2_o = (a2_o - t2_o) * a2_o * (1 - a2_o)\n",
    "\n",
    "    delta1_h = ((delta1_o * w1_o1) + (delta2_o * w1_o2)) * a1_h * (1 - a1_h)\n",
    "    delta2_h = ((delta1_o * w2_o1) + (delta2_o * w2_o2)) * a2_h * (1 - a2_h)\n",
    "\n",
    "    w1_o1_new = w1_o1 - (learning_rate * delta1_o * a1_h)\n",
    "    w1_o2_new = w1_o2 - (learning_rate * delta2_o * a1_h)\n",
    "    b1_o_new = b1_o - (learning_rate * delta1_o)\n",
    "    b2_o_new = b2_o - (learning_rate * delta2_o)\n",
    "\n",
    "    w1_h1_new = w1_h1 - (learning_rate * delta1_h * x1)\n",
    "    w1_h2_new = w1_h2 - (learning_rate * delta2_h * x1)\n",
    "    w2_h1_new = w2_h1 - (learning_rate * delta1_h * x2)\n",
    "    w2_h2_new = w2_h2 - (learning_rate * delta2_h * x2)\n",
    "    b1_h_new = b1_h - (learning_rate * delta1_h)\n",
    "    b2_h_new = b2_h - (learning_rate * delta2_h)\n",
    "\n",
    "    # Update weights and biases\n",
    "    w1_o1 = w1_o1_new\n",
    "    w1_o2 = w1_o2_new\n",
    "    b1_o = b1_o_new\n",
    "    b2_o = b2_o_new\n",
    "\n",
    "    w1_h1 = w1_h1_new\n",
    "    w1_h2 = w1_h2_new\n",
    "    w2_h1 = w2_h1_new\n",
    "    w2_h2 = w2_h2_new\n",
    "    b1_h = b1_h_new\n",
    "    b2_h = b2_h_new\n",
    "\n",
    "# Print the final weights and biases\n",
    "print(\"Final Weights and Biases:\")\n",
    "print(\"w1_h1:\", w1_h1)\n",
    "print(\"w1_h2:\", w1_h2)\n",
    "print(\"w2_h1:\", w2_h1)\n",
    "print(\"w2_h2:\", w2_h2)\n",
    "print(\"w1_o1:\", w1_o1)\n",
    "print(\"w1_o2:\", w1_o2)\n",
    "print(\"b1_h:\", b1_h)\n",
    "print(\"b2_h:\", b2_h)\n",
    "print(\"b1_o:\", b1_o)\n",
    "print(\"b2_o:\", b2_o)\n",
    "\n",
    "# Print the final outputs and total error\n",
    "print(\"Final Outputs (a1_o, a2_o):\", a1_o, a2_o)\n",
    "print(\"Total Error:\", total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs (a1_o, a2_o): 0.7569319154399385 0.7677178798069613\n",
      "Total Error: 0.303658313630144\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Inputs\n",
    "x1 = 0.05\n",
    "x2 = 0.10\n",
    "\n",
    "# Biases\n",
    "b1_h = 0.35\n",
    "b2_h = 0.35\n",
    "b1_o = 0.60\n",
    "b2_o = 0.60\n",
    "\n",
    "# Weights\n",
    "w1_h1 = 0.15\n",
    "w1_h2 = 0.20\n",
    "w2_h1 = 0.25\n",
    "w2_h2 = 0.30\n",
    "w1_o1 = 0.40\n",
    "w1_o2 = 0.45\n",
    "w2_o1 = 0.50\n",
    "w2_o2 = 0.55\n",
    "\n",
    "# Target values\n",
    "t1_o = 0.01\n",
    "t2_o = 0.99\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Forward Pass\n",
    "z1_h = (x1 * w1_h1) + (x2 * w2_h1) + b1_h\n",
    "z2_h = (x1 * w1_h2) + (x2 * w2_h2) + b2_h\n",
    "a1_h = sigmoid(z1_h)\n",
    "a2_h = sigmoid(z2_h)\n",
    "z1_o = (a1_h * w1_o1) + (a2_h * w2_o1) + b1_o\n",
    "z2_o = (a1_h * w1_o2) + (a2_h * w2_o2) + b2_o\n",
    "a1_o = sigmoid(z1_o)\n",
    "a2_o = sigmoid(z2_o)\n",
    "\n",
    "# Calculate the error\n",
    "E1_o = 0.5 * (t1_o - a1_o)**2\n",
    "E2_o = 0.5 * (t2_o - a2_o)**2\n",
    "\n",
    "# Total error\n",
    "total_error = E1_o + E2_o\n",
    "\n",
    "# Print the results for one iteration\n",
    "print(\"Outputs (a1_o, a2_o):\", a1_o, a2_o)\n",
    "print(\"Total Error:\", total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered Details:\n",
      "x1 = 0.05\n",
      "x2 = 0.1\n",
      "b1_h = 0.35\n",
      "b2_h = 0.35\n",
      "b1_o = 0.6\n",
      "b2_o = 0.6\n",
      "w1_h1 = 0.15\n",
      "w1_h2 = 0.2\n",
      "w2_h1 = 0.25\n",
      "w2_h2 = 0.3\n",
      "w1_o1 = 0.4\n",
      "w1_o2 = 0.45\n",
      "w2_o1 = 0.5\n",
      "w2_o2 = 0.55\n",
      "t1_o = 0.01\n",
      "t2_o = 0.99\n",
      "learning_rate = 0.5\n",
      "\n",
      "Forward Pass (Iteration 1):\n",
      "a1_h = 0.5944759307482401\n",
      "a2_h = 0.5962826992967878\n",
      "a1_o = 0.7569319154399385\n",
      "a2_o = 0.7677178798069613\n",
      "\n",
      "Backward Pass (Iteration 1):\n",
      "delta1_o = 0.13742500854354509\n",
      "delta2_o = -0.039638934062896716\n",
      "delta1_h = 0.00895168731261501\n",
      "delta2_h = 0.011292890022218964\n",
      "\n",
      "Updating of Weights (Iteration 1):\n",
      "w1_o1_new = 0.35915207006899563\n",
      "w1_o2_new = 0.46178219611045435\n",
      "b1_o_new = 0.5312874957282274\n",
      "b2_o_new = 0.6198194670314483\n",
      "w1_h1_new = 0.14977620781718462\n",
      "w1_h2_new = 0.19971767774944454\n",
      "w2_h1_new = 0.24955241563436925\n",
      "w2_h2_new = 0.29943535549888906\n",
      "b1_h_new = 0.3455241563436925\n",
      "b2_h_new = 0.3443535549888905\n",
      "\n",
      "Total Error (Iteration 1): 0.303658313630144\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Given Details\n",
    "x1 = 0.05\n",
    "x2 = 0.10\n",
    "b1_h = 0.35\n",
    "b2_h = 0.35\n",
    "b1_o = 0.60\n",
    "b2_o = 0.60\n",
    "w1_h1 = 0.15\n",
    "w1_h2 = 0.20\n",
    "w2_h1 = 0.25\n",
    "w2_h2 = 0.30\n",
    "w1_o1 = 0.40\n",
    "w1_o2 = 0.45\n",
    "w2_o1 = 0.50\n",
    "w2_o2 = 0.55\n",
    "t1_o = 0.01\n",
    "t2_o = 0.99\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Forward Pass (Iteration 1)\n",
    "# Hidden layer\n",
    "z1_h = (x1 * w1_h1) + (x2 * w2_h1) + b1_h\n",
    "z2_h = (x1 * w1_h2) + (x2 * w2_h2) + b2_h\n",
    "a1_h = sigmoid(z1_h)\n",
    "a2_h = sigmoid(z2_h)\n",
    "\n",
    "# Output layer\n",
    "z1_o = (a1_h * w1_o1) + (a2_h * w2_o1) + b1_o\n",
    "z2_o = (a1_h * w1_o2) + (a2_h * w2_o2) + b2_o\n",
    "a1_o = sigmoid(z1_o)\n",
    "a2_o = sigmoid(z2_o)\n",
    "\n",
    "# Calculate the error\n",
    "E1_o = 0.5 * (t1_o - a1_o)**2\n",
    "E2_o = 0.5 * (t2_o - a2_o)**2\n",
    "total_error = E1_o + E2_o\n",
    "\n",
    "# Backward Pass (Iteration 1)\n",
    "# Output layer\n",
    "delta1_o = (a1_o - t1_o) * a1_o * (1 - a1_o)\n",
    "delta2_o = (a2_o - t2_o) * a2_o * (1 - a2_o)\n",
    "\n",
    "# Hidden layer\n",
    "delta1_h = ((delta1_o * w1_o1) + (delta2_o * w1_o2)) * a1_h * (1 - a1_h)\n",
    "delta2_h = ((delta1_o * w2_o1) + (delta2_o * w2_o2)) * a2_h * (1 - a2_h)\n",
    "\n",
    "# Updating of Weights (Iteration 1)\n",
    "# Output layer\n",
    "w1_o1_new = w1_o1 - (learning_rate * delta1_o * a1_h)\n",
    "w1_o2_new = w1_o2 - (learning_rate * delta2_o * a1_h)\n",
    "b1_o_new = b1_o - (learning_rate * delta1_o)\n",
    "b2_o_new = b2_o - (learning_rate * delta2_o)\n",
    "\n",
    "# Hidden layer\n",
    "w1_h1_new = w1_h1 - (learning_rate * delta1_h * x1)\n",
    "w1_h2_new = w1_h2 - (learning_rate * delta2_h * x1)\n",
    "w2_h1_new = w2_h1 - (learning_rate * delta1_h * x2)\n",
    "w2_h2_new = w2_h2 - (learning_rate * delta2_h * x2)\n",
    "b1_h_new = b1_h - (learning_rate * delta1_h)\n",
    "b2_h_new = b2_h - (learning_rate * delta2_h)\n",
    "\n",
    "# Display all the entered details and results for Iteration 1\n",
    "print(\"Entered Details:\")\n",
    "print(\"x1 =\", x1)\n",
    "print(\"x2 =\", x2)\n",
    "print(\"b1_h =\", b1_h)\n",
    "print(\"b2_h =\", b2_h)\n",
    "print(\"b1_o =\", b1_o)\n",
    "print(\"b2_o =\", b2_o)\n",
    "print(\"w1_h1 =\", w1_h1)\n",
    "print(\"w1_h2 =\", w1_h2)\n",
    "print(\"w2_h1 =\", w2_h1)\n",
    "print(\"w2_h2 =\", w2_h2)\n",
    "print(\"w1_o1 =\", w1_o1)\n",
    "print(\"w1_o2 =\", w1_o2)\n",
    "print(\"w2_o1 =\", w2_o1)\n",
    "print(\"w2_o2 =\", w2_o2)\n",
    "print(\"t1_o =\", t1_o)\n",
    "print(\"t2_o =\", t2_o)\n",
    "print(\"learning_rate =\", learning_rate)\n",
    "\n",
    "print(\"\\nForward Pass (Iteration 1):\")\n",
    "print(\"a1_h =\", a1_h)\n",
    "print(\"a2_h =\", a2_h)\n",
    "print(\"a1_o =\", a1_o)\n",
    "print(\"a2_o =\", a2_o)\n",
    "\n",
    "print(\"\\nBackward Pass (Iteration 1):\")\n",
    "print(\"delta1_o =\", delta1_o)\n",
    "print(\"delta2_o =\", delta2_o)\n",
    "print(\"delta1_h =\", delta1_h)\n",
    "print(\"delta2_h =\", delta2_h)\n",
    "\n",
    "print(\"\\nUpdating of Weights (Iteration 1):\")\n",
    "print(\"w1_o1_new =\", w1_o1_new)\n",
    "print(\"w1_o2_new =\", w1_o2_new)\n",
    "print(\"b1_o_new =\", b1_o_new)\n",
    "print(\"b2_o_new =\", b2_o_new)\n",
    "print(\"w1_h1_new =\", w1_h1_new)\n",
    "print(\"w1_h2_new =\", w1_h2_new)\n",
    "print(\"w2_h1_new =\", w2_h1_new)\n",
    "print(\"w2_h2_new =\", w2_h2_new)\n",
    "print(\"b1_h_new =\", b1_h_new)\n",
    "print(\"b2_h_new =\", b2_h_new)\n",
    "\n",
    "print(\"\\nTotal Error (Iteration 1):\", total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Iterations: 100000\n",
      "Minimum Error: 0.303658313630144\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Given Details\n",
    "# ... (same as before)\n",
    "\n",
    "# Target Error Threshold\n",
    "target_error_threshold = 0.001  # You can adjust this value\n",
    "\n",
    "# Maximum Number of Iterations\n",
    "max_iterations = 100000  # You can adjust this value\n",
    "\n",
    "# Initialize weights and biases (same as before)\n",
    "\n",
    "# Training loop\n",
    "for iteration in range(max_iterations):\n",
    "    # Forward Pass (same as before)\n",
    "    # ...\n",
    "\n",
    "    # Calculate the error (same as before)\n",
    "    # ...\n",
    "\n",
    "    # Backward Pass and Weight Updates (same as before)\n",
    "    # ...\n",
    "\n",
    "    # Check if the error has reached the target threshold\n",
    "    if total_error < target_error_threshold:\n",
    "        break\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of Iterations:\", iteration + 1)\n",
    "print(\"Minimum Error:\", total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass (Iteration 1):\n",
      "a1_h = 0.5944759307482401\n",
      "a2_h = 0.5962826992967878\n",
      "a1_o = 0.7569319154399385\n",
      "a2_o = 0.7677178798069613\n",
      "\n",
      "Total Error after Backpropagation (Iteration 1): 0.303658313630144\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Given Details\n",
    "x1 = 0.05\n",
    "x2 = 0.10\n",
    "b1_h = 0.35\n",
    "b2_h = 0.35\n",
    "b1_o = 0.60\n",
    "b2_o = 0.60\n",
    "w1_h1 = 0.15\n",
    "w1_h2 = 0.20\n",
    "w2_h1 = 0.25\n",
    "w2_h2 = 0.30\n",
    "w1_o1 = 0.40\n",
    "w1_o2 = 0.45\n",
    "w2_o1 = 0.50\n",
    "w2_o2 = 0.55\n",
    "t1_o = 0.01\n",
    "t2_o = 0.99\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Forward Pass (Iteration 1)\n",
    "# Hidden layer\n",
    "z1_h = (x1 * w1_h1) + (x2 * w2_h1) + b1_h\n",
    "z2_h = (x1 * w1_h2) + (x2 * w2_h2) + b2_h\n",
    "a1_h = sigmoid(z1_h)\n",
    "a2_h = sigmoid(z2_h)\n",
    "\n",
    "# Output layer\n",
    "z1_o = (a1_h * w1_o1) + (a2_h * w2_o1) + b1_o\n",
    "z2_o = (a1_h * w1_o2) + (a2_h * w2_o2) + b2_o\n",
    "a1_o = sigmoid(z1_o)\n",
    "a2_o = sigmoid(z2_o)\n",
    "\n",
    "# Calculate the error\n",
    "E1_o = 0.5 * (t1_o - a1_o)**2\n",
    "E2_o = 0.5 * (t2_o - a2_o)**2\n",
    "total_error = E1_o + E2_o\n",
    "\n",
    "# Backward Pass (Iteration 1)\n",
    "# Output layer\n",
    "delta1_o = (a1_o - t1_o) * a1_o * (1 - a1_o)\n",
    "delta2_o = (a2_o - t2_o) * a2_o * (1 - a2_o)\n",
    "\n",
    "# Hidden layer\n",
    "delta1_h = ((delta1_o * w1_o1) + (delta2_o * w1_o2)) * a1_h * (1 - a1_h)\n",
    "delta2_h = ((delta1_o * w2_o1) + (delta2_o * w2_o2)) * a2_h * (1 - a2_h)\n",
    "\n",
    "# Updating of Weights (Iteration 1)\n",
    "# Output layer\n",
    "w1_o1_new = w1_o1 - (learning_rate * delta1_o * a1_h)\n",
    "w1_o2_new = w1_o2 - (learning_rate * delta2_o * a1_h)\n",
    "b1_o_new = b1_o - (learning_rate * delta1_o)\n",
    "b2_o_new = b2_o - (learning_rate * delta2_o)\n",
    "\n",
    "# Hidden layer\n",
    "w1_h1_new = w1_h1 - (learning_rate * delta1_h * x1)\n",
    "w1_h2_new = w1_h2 - (learning_rate * delta2_h * x1)\n",
    "w2_h1_new = w2_h1 - (learning_rate * delta1_h * x2)\n",
    "w2_h2_new = w2_h2 - (learning_rate * delta2_h * x2)\n",
    "b1_h_new = b1_h - (learning_rate * delta1_h)\n",
    "b2_h_new = b2_h - (learning_rate * delta2_h)\n",
    "\n",
    "# Display the results\n",
    "print(\"Forward Pass (Iteration 1):\")\n",
    "print(\"a1_h =\", a1_h)\n",
    "print(\"a2_h =\", a2_h)\n",
    "print(\"a1_o =\", a1_o)\n",
    "print(\"a2_o =\", a2_o)\n",
    "\n",
    "print(\"\\nTotal Error after Backpropagation (Iteration 1):\", total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass (Iteration 1):\n",
      "a1_h = 0.5944759307482401\n",
      "a2_h = 0.5962826992967878\n",
      "a1_o = 0.7569319154399385\n",
      "a2_o = 0.7677178798069613\n",
      "\n",
      "Total Error after Backpropagation (Iteration 1): 0.303658313630144\n",
      "\n",
      "Number of Iterations: 10000\n",
      "Minimum Error: 0.303658313630144\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Given Details\n",
    "x1 = 0.05\n",
    "x2 = 0.10\n",
    "b1_h = 0.35\n",
    "b2_h = 0.35\n",
    "b1_o = 0.60\n",
    "b2_o = 0.60\n",
    "w1_h1 = 0.15\n",
    "w1_h2 = 0.20\n",
    "w2_h1 = 0.25\n",
    "w2_h2 = 0.30\n",
    "w1_o1 = 0.40\n",
    "w1_o2 = 0.45\n",
    "w2_o1 = 0.50\n",
    "w2_o2 = 0.55\n",
    "t1_o = 0.01\n",
    "t2_o = 0.99\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Target Error Threshold\n",
    "target_error_threshold = 0.001\n",
    "\n",
    "# Initialize weights and biases (same as before)\n",
    "\n",
    "# Training loop\n",
    "for iteration in range(10000):  # Maximum of 10,000 iterations\n",
    "    # Forward Pass (same as before)\n",
    "    # ...\n",
    "\n",
    "    # Calculate the error (same as before)\n",
    "    # ...\n",
    "\n",
    "    # Backward Pass and Weight Updates (same as before)\n",
    "    # ...\n",
    "\n",
    "    # Check if the error has reached the target threshold\n",
    "    if total_error < target_error_threshold:\n",
    "        break\n",
    "\n",
    "# Print the results\n",
    "print(\"Forward Pass (Iteration 1):\")\n",
    "print(\"a1_h =\", a1_h)\n",
    "print(\"a2_h =\", a2_h)\n",
    "print(\"a1_o =\", a1_o)\n",
    "print(\"a2_o =\", a2_o)\n",
    "\n",
    "print(\"\\nTotal Error after Backpropagation (Iteration 1):\", total_error)\n",
    "\n",
    "# Print the number of iterations and the minimum error achieved\n",
    "print(\"\\nNumber of Iterations:\", iteration + 1)\n",
    "print(\"Minimum Error:\", total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass (Iteration 1):\n",
      "a1_h = 0.7222952839947697\n",
      "a2_h = 0.5506832299025011\n",
      "a1_o = 0.04222167902795929\n",
      "a2_o = 0.9590513729917712\n",
      "\n",
      "Total Error after Backpropagation (Iteration 1): 0.000998027056537649\n",
      "\n",
      "Number of Iterations: 505\n",
      "Minimum Error: 0.000998027056537649\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Given Details\n",
    "x1 = 0.05\n",
    "x2 = 0.10\n",
    "b1_h = 0.35\n",
    "b2_h = 0.35\n",
    "b1_o = 0.60\n",
    "b2_o = 0.60\n",
    "w1_h1 = 0.15\n",
    "w1_h2 = 0.20\n",
    "w2_h1 = 0.25\n",
    "w2_h2 = 0.30\n",
    "w1_o1 = 0.40\n",
    "w1_o2 = 0.45\n",
    "w2_o1 = 0.50\n",
    "w2_o2 = 0.55\n",
    "t1_o = 0.01\n",
    "t2_o = 0.99\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Target Error Threshold\n",
    "target_error_threshold = 0.001\n",
    "\n",
    "# Maximum Number of Iterations\n",
    "max_iterations = 10000\n",
    "\n",
    "# Initialize weights and biases (same as before)\n",
    "\n",
    "# Training loop\n",
    "for iteration in range(max_iterations):\n",
    "    # Forward Pass (Iteration 1)\n",
    "    # Hidden layer\n",
    "    z1_h = (x1 * w1_h1) + (x2 * w2_h1) + b1_h\n",
    "    z2_h = (x1 * w1_h2) + (x2 * w2_h2) + b2_h\n",
    "    a1_h = sigmoid(z1_h)\n",
    "    a2_h = sigmoid(z2_h)\n",
    "\n",
    "    # Output layer\n",
    "    z1_o = (a1_h * w1_o1) + (a2_h * w2_o1) + b1_o\n",
    "    z2_o = (a1_h * w1_o2) + (a2_h * w2_o2) + b2_o\n",
    "    a1_o = sigmoid(z1_o)\n",
    "    a2_o = sigmoid(z2_o)\n",
    "\n",
    "    # Calculate the error\n",
    "    E1_o = 0.5 * (t1_o - a1_o)**2\n",
    "    E2_o = 0.5 * (t2_o - a2_o)**2\n",
    "    total_error = E1_o + E2_o\n",
    "\n",
    "    # Backward Pass and Weight Updates\n",
    "    # Output layer\n",
    "    delta1_o = (a1_o - t1_o) * a1_o * (1 - a1_o)\n",
    "    delta2_o = (a2_o - t2_o) * a2_o * (1 - a2_o)\n",
    "    \n",
    "    w1_o1_new = w1_o1 - (learning_rate * delta1_o * a1_h)\n",
    "    w1_o2_new = w1_o2 - (learning_rate * delta2_o * a1_h)\n",
    "    b1_o_new = b1_o - (learning_rate * delta1_o)\n",
    "    b2_o_new = b2_o - (learning_rate * delta2_o)\n",
    "\n",
    "    # Hidden layer\n",
    "    delta1_h = ((delta1_o * w1_o1) + (delta2_o * w1_o2)) * a1_h * (1 - a1_h)\n",
    "    delta2_h = ((delta1_o * w2_o1) + (delta2_o * w2_o2)) * a2_h * (1 - a2_h)\n",
    "    \n",
    "    w1_h1_new = w1_h1 - (learning_rate * delta1_h * x1)\n",
    "    w1_h2_new = w1_h2 - (learning_rate * delta2_h * x1)\n",
    "    w2_h1_new = w2_h1 - (learning_rate * delta1_h * x2)\n",
    "    w2_h2_new = w2_h2 - (learning_rate * delta2_h * x2)\n",
    "    b1_h_new = b1_h - (learning_rate * delta1_h)\n",
    "    b2_h_new = b2_h - (learning_rate * delta2_h)\n",
    "\n",
    "    # Update weights and biases for the next iteration\n",
    "    w1_o1, w1_o2, b1_o, b2_o = w1_o1_new, w1_o2_new, b1_o_new, b2_o_new\n",
    "    w1_h1, w1_h2, w2_h1, w2_h2 = w1_h1_new, w1_h2_new, w2_h1_new, w2_h2_new\n",
    "    b1_h, b2_h = b1_h_new, b2_h_new\n",
    "\n",
    "    # Check if the error has reached the target threshold\n",
    "    if total_error < target_error_threshold:\n",
    "        break\n",
    "\n",
    "# Print the results\n",
    "print(\"Forward Pass (Iteration 1):\")\n",
    "print(\"a1_h =\", a1_h)\n",
    "print(\"a2_h =\", a2_h)\n",
    "print(\"a1_o =\", a1_o)\n",
    "print(\"a2_o =\", a2_o)\n",
    "\n",
    "print(\"\\nTotal Error after Backpropagation (Iteration 1):\", total_error)\n",
    "\n",
    "# Print the number of iterations and the minimum error\n",
    "# ... (previous code)\n",
    "\n",
    "# Print the number of iterations and the minimum error achieved\n",
    "print(\"\\nNumber of Iterations:\", iteration + 1)\n",
    "print(\"Minimum Error:\", total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass (Iteration 1):\n",
      "a1_h = 0.7276911554702422\n",
      "a2_h = 0.6629256876062106\n",
      "a1_o = 0.042189118601334806\n",
      "a2_o = 0.9590126924110401\n",
      "\n",
      "Total Error after Backpropagation (Iteration 1): 0.0009981762939718034\n",
      "\n",
      "Number of Iterations: 500\n",
      "Minimum Error: 0.0009981762939718034\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Given Details\n",
    "x1 = 0.05\n",
    "x2 = 0.10\n",
    "b1_h = 0.35\n",
    "b2_h = 0.35\n",
    "b1_o = 0.60\n",
    "b2_o = 0.60\n",
    "w1_h1 = 0.15\n",
    "w1_h2 = 0.20\n",
    "w2_h1 = 0.25\n",
    "w2_h2 = 0.30\n",
    "w1_o1 = 0.40\n",
    "w1_o2 = 0.45\n",
    "w2_o1 = 0.50\n",
    "w2_o2 = 0.55\n",
    "t1_o = 0.01\n",
    "t2_o = 0.99\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Target Error Threshold\n",
    "target_error_threshold = 0.001\n",
    "\n",
    "# Maximum Number of Iterations\n",
    "max_iterations = 10000\n",
    "\n",
    "# Initialize weights and biases differently\n",
    "np.random.seed(42)  # For reproducibility\n",
    "w1_h1 = np.random.rand()\n",
    "w1_h2 = np.random.rand()\n",
    "w2_h1 = np.random.rand()\n",
    "w2_h2 = np.random.rand()\n",
    "w1_o1 = np.random.rand()\n",
    "w1_o2 = np.random.rand()\n",
    "w2_o1 = np.random.rand()\n",
    "w2_o2 = np.random.rand()\n",
    "\n",
    "# Training loop\n",
    "for iteration in range(max_iterations):\n",
    "    # Forward Pass (Iteration 1)\n",
    "    # Hidden layer\n",
    "    z1_h = (x1 * w1_h1) + (x2 * w2_h1) + b1_h\n",
    "    z2_h = (x1 * w1_h2) + (x2 * w2_h2) + b2_h\n",
    "    a1_h = sigmoid(z1_h)\n",
    "    a2_h = sigmoid(z2_h)\n",
    "\n",
    "    # Output layer\n",
    "    z1_o = (a1_h * w1_o1) + (a2_h * w2_o1) + b1_o\n",
    "    z2_o = (a1_h * w1_o2) + (a2_h * w2_o2) + b2_o\n",
    "    a1_o = sigmoid(z1_o)\n",
    "    a2_o = sigmoid(z2_o)\n",
    "\n",
    "    # Calculate the error\n",
    "    E1_o = 0.5 * (t1_o - a1_o)**2\n",
    "    E2_o = 0.5 * (t2_o - a2_o)**2\n",
    "    total_error = E1_o + E2_o\n",
    "\n",
    "    # Backward Pass and Weight Updates\n",
    "    # Output layer\n",
    "    delta1_o = (a1_o - t1_o) * a1_o * (1 - a1_o)\n",
    "    delta2_o = (a2_o - t2_o) * a2_o * (1 - a2_o)\n",
    "    \n",
    "    w1_o1_new = w1_o1 - (learning_rate * delta1_o * a1_h)\n",
    "    w1_o2_new = w1_o2 - (learning_rate * delta2_o * a1_h)\n",
    "    b1_o_new = b1_o - (learning_rate * delta1_o)\n",
    "    b2_o_new = b2_o - (learning_rate * delta2_o)\n",
    "\n",
    "    # Hidden layer\n",
    "    delta1_h = ((delta1_o * w1_o1) + (delta2_o * w1_o2)) * a1_h * (1 - a1_h)\n",
    "    delta2_h = ((delta1_o * w2_o1) + (delta2_o * w2_o2)) * a2_h * (1 - a2_h)\n",
    "    \n",
    "    w1_h1_new = w1_h1 - (learning_rate * delta1_h * x1)\n",
    "    w1_h2_new = w1_h2 - (learning_rate * delta2_h * x1)\n",
    "    w2_h1_new = w2_h1 - (learning_rate * delta1_h * x2)\n",
    "    w2_h2_new = w2_h2 - (learning_rate * delta2_h * x2)\n",
    "    b1_h_new = b1_h - (learning_rate * delta1_h)\n",
    "    b2_h_new = b2_h - (learning_rate * delta2_h)\n",
    "\n",
    "    # Update weights and biases for the next iteration\n",
    "    w1_o1, w1_o2, b1_o, b2_o = w1_o1_new, w1_o2_new, b1_o_new, b2_o_new\n",
    "    w1_h1, w1_h2, w2_h1, w2_h2 = w1_h1_new, w1_h2_new, w2_h1_new, w2_h2_new\n",
    "    b1_h, b2_h = b1_h_new, b2_h_new\n",
    "\n",
    "    # Check if the error has reached the target threshold\n",
    "    if total_error < target_error_threshold:\n",
    "        break\n",
    "\n",
    "# Print the results\n",
    "print(\"Forward Pass (Iteration 1):\")\n",
    "print(\"a1_h =\", a1_h)\n",
    "print(\"a2_h =\", a2_h)\n",
    "print(\"a1_o =\", a1_o)\n",
    "print(\"a2_o =\", a2_o)\n",
    "\n",
    "print(\"\\nTotal Error after Backpropagation (Iteration 1):\", total_error)\n",
    "\n",
    "# Print the number of iterations and the minimum error achieved\n",
    "print(\"\\nNumber of Iterations:\", iteration + 1)\n",
    "print(\"Minimum Error:\", total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass (Iteration 1):\n",
      "a1_h = 0.7276911554702422\n",
      "a2_h = 0.6629256876062106\n",
      "a1_o = 0.042189118601334806\n",
      "a2_o = 0.9590126924110401\n",
      "\n",
      "Total Error after Backpropagation (Iteration 1): 0.0009981762939718034\n",
      "\n",
      "Number of Iterations: 500\n",
      "Minimum Error: 0.0009981762939718034\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Given Details\n",
    "x1 = 0.05\n",
    "x2 = 0.10\n",
    "b1_h = 0.35\n",
    "b2_h = 0.35\n",
    "b1_o = 0.60\n",
    "b2_o = 0.60\n",
    "w1_h1 = 0.15\n",
    "w1_h2 = 0.20\n",
    "w2_h1 = 0.25\n",
    "w2_h2 = 0.30\n",
    "w1_o1 = 0.40\n",
    "w1_o2 = 0.45\n",
    "w2_o1 = 0.50\n",
    "w2_o2 = 0.55\n",
    "t1_o = 0.01\n",
    "t2_o = 0.99\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Target Error Threshold\n",
    "target_error_threshold = 0.001\n",
    "\n",
    "# Maximum Number of Iterations\n",
    "max_iterations = 10000\n",
    "\n",
    "# Initialize weights and biases\n",
    "np.random.seed(42)  # For reproducibility\n",
    "w1_h1 = np.random.rand()\n",
    "w1_h2 = np.random.rand()\n",
    "w2_h1 = np.random.rand()\n",
    "w2_h2 = np.random.rand()\n",
    "w1_o1 = np.random.rand()\n",
    "w1_o2 = np.random.rand()\n",
    "w2_o1 = np.random.rand()\n",
    "w2_o2 = np.random.rand()\n",
    "\n",
    "# Training loop\n",
    "for iteration in range(max_iterations):\n",
    "    # Forward Pass\n",
    "    z1_h = (x1 * w1_h1) + (x2 * w2_h1) + b1_h\n",
    "    z2_h = (x1 * w1_h2) + (x2 * w2_h2) + b2_h\n",
    "    a1_h = sigmoid(z1_h)\n",
    "    a2_h = sigmoid(z2_h)\n",
    "\n",
    "    z1_o = (a1_h * w1_o1) + (a2_h * w2_o1) + b1_o\n",
    "    z2_o = (a1_h * w1_o2) + (a2_h * w2_o2) + b2_o\n",
    "    a1_o = sigmoid(z1_o)\n",
    "    a2_o = sigmoid(z2_o)\n",
    "\n",
    "    # Calculate Error\n",
    "    E1_o = 0.5 * (t1_o - a1_o)**2\n",
    "    E2_o = 0.5 * (t2_o - a2_o)**2\n",
    "    total_error = E1_o + E2_o\n",
    "\n",
    "    # Backward Pass\n",
    "    delta1_o = (a1_o - t1_o) * a1_o * (1 - a1_o)\n",
    "    delta2_o = (a2_o - t2_o) * a2_o * (1 - a2_o)\n",
    "\n",
    "    delta1_h = ((delta1_o * w1_o1) + (delta2_o * w1_o2)) * a1_h * (1 - a1_h)\n",
    "    delta2_h = ((delta1_o * w2_o1) + (delta2_o * w2_o2)) * a2_h * (1 - a2_h)\n",
    "\n",
    "    # Weight Updates\n",
    "    w1_o1_new = w1_o1 - (learning_rate * delta1_o * a1_h)\n",
    "    w1_o2_new = w1_o2 - (learning_rate * delta2_o * a1_h)\n",
    "    b1_o_new = b1_o - (learning_rate * delta1_o)\n",
    "    b2_o_new = b2_o - (learning_rate * delta2_o)\n",
    "\n",
    "    w1_h1_new = w1_h1 - (learning_rate * delta1_h * x1)\n",
    "    w1_h2_new = w1_h2 - (learning_rate * delta2_h * x1)\n",
    "    w2_h1_new = w2_h1 - (learning_rate * delta1_h * x2)\n",
    "    w2_h2_new = w2_h2 - (learning_rate * delta2_h * x2)\n",
    "    b1_h_new = b1_h - (learning_rate * delta1_h)\n",
    "    b2_h_new = b2_h - (learning_rate * delta2_h)\n",
    "\n",
    "    # Update weights and biases\n",
    "    w1_o1, w1_o2, b1_o, b2_o = w1_o1_new, w1_o2_new, b1_o_new, b2_o_new\n",
    "    w1_h1, w1_h2, w2_h1, w2_h2 = w1_h1_new, w1_h2_new, w2_h1_new, w2_h2_new\n",
    "    b1_h, b2_h = b1_h_new, b2_h_new\n",
    "\n",
    "    # Check if the error has reached the target threshold\n",
    "    if total_error < target_error_threshold:\n",
    "        break\n",
    "\n",
    "# Print the results\n",
    "print(\"Forward Pass (Iteration 1):\")\n",
    "print(\"a1_h =\", a1_h)\n",
    "print(\"a2_h =\", a2_h)\n",
    "print(\"a1_o =\", a1_o)\n",
    "print(\"a2_o =\", a2_o)\n",
    "\n",
    "print(\"\\nTotal Error after Backpropagation (Iteration 1):\", total_error)\n",
    "\n",
    "# Print the number of iterations and the minimum error achieved\n",
    "print(\"\\nNumber of Iterations:\", iteration+1)\n",
    "print(\"Minimum Error:\", total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass (Iteration 1):\n",
      "a1_h = 0.7276911554702422\n",
      "a2_h = 0.6629256876062106\n",
      "a1_o = 0.042189118601334806\n",
      "a2_o = 0.9590126924110401\n",
      "\n",
      "Total Error after Backpropagation (Iteration 1): 0.0009981762939718034\n",
      "\n",
      "Number of Iterations: 500\n",
      "Minimum Error: 0.0009981762939718034\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Given Details\n",
    "x1 = 0.05\n",
    "x2 = 0.10\n",
    "b1_h = 0.35\n",
    "b2_h = 0.35\n",
    "b1_o = 0.60\n",
    "b2_o = 0.60\n",
    "w1_h1 = 0.15\n",
    "w1_h2 = 0.20\n",
    "w2_h1 = 0.25\n",
    "w2_h2 = 0.30\n",
    "w1_o1 = 0.40\n",
    "w1_o2 = 0.45\n",
    "w2_o1 = 0.50\n",
    "w2_o2 = 0.55\n",
    "t1_o = 0.01\n",
    "t2_o = 0.99\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Target Error Threshold\n",
    "target_error_threshold = 0.001\n",
    "\n",
    "# Maximum Number of Iterations\n",
    "max_iterations = 10000\n",
    "\n",
    "# Initialize weights and biases differently\n",
    "np.random.seed(42)  # For reproducibility\n",
    "w1_h1 = np.random.rand()\n",
    "w1_h2 = np.random.rand()\n",
    "w2_h1 = np.random.rand()\n",
    "w2_h2 = np.random.rand()\n",
    "w1_o1 = np.random.rand()\n",
    "w1_o2 = np.random.rand()\n",
    "w2_o1 = np.random.rand()\n",
    "w2_o2 = np.random.rand()\n",
    "\n",
    "# Training loop\n",
    "for iteration in range(max_iterations):\n",
    "    # Forward Pass\n",
    "    z1_h = (x1 * w1_h1) + (x2 * w2_h1) + b1_h\n",
    "    z2_h = (x1 * w1_h2) + (x2 * w2_h2) + b2_h\n",
    "    a1_h = sigmoid(z1_h)\n",
    "    a2_h = sigmoid(z2_h)\n",
    "\n",
    "    z1_o = (a1_h * w1_o1) + (a2_h * w2_o1) + b1_o\n",
    "    z2_o = (a1_h * w1_o2) + (a2_h * w2_o2) + b2_o\n",
    "    a1_o = sigmoid(z1_o)\n",
    "    a2_o = sigmoid(z2_o)\n",
    "\n",
    "    # Calculate Error\n",
    "    E1_o = 0.5 * (t1_o - a1_o)**2\n",
    "    E2_o = 0.5 * (t2_o - a2_o)**2\n",
    "    total_error = E1_o + E2_o\n",
    "\n",
    "    # Backward Pass\n",
    "    delta1_o = (a1_o - t1_o) * a1_o * (1 - a1_o)\n",
    "    delta2_o = (a2_o - t2_o) * a2_o * (1 - a2_o)\n",
    "\n",
    "    delta1_h = ((delta1_o * w1_o1) + (delta2_o * w1_o2)) * a1_h * (1 - a1_h)\n",
    "    delta2_h = ((delta1_o * w2_o1) + (delta2_o * w2_o2)) * a2_h * (1 - a2_h)\n",
    "\n",
    "    # Weight Updates\n",
    "    w1_o1_new = w1_o1 - (learning_rate * delta1_o * a1_h)\n",
    "    w1_o2_new = w1_o2 - (learning_rate * delta2_o * a1_h)\n",
    "    b1_o_new = b1_o - (learning_rate * delta1_o)\n",
    "    b2_o_new = b2_o - (learning_rate * delta2_o)\n",
    "\n",
    "    w1_h1_new = w1_h1 - (learning_rate * delta1_h * x1)\n",
    "    w1_h2_new = w1_h2 - (learning_rate * delta2_h * x1)\n",
    "    w2_h1_new = w2_h1 - (learning_rate * delta1_h * x2)\n",
    "    w2_h2_new = w2_h2 - (learning_rate * delta2_h * x2)\n",
    "    b1_h_new = b1_h - (learning_rate * delta1_h)\n",
    "    b2_h_new = b2_h - (learning_rate * delta2_h)\n",
    "\n",
    "    # Update weights and biases for the next iteration\n",
    "    w1_o1, w1_o2, b1_o, b2_o = w1_o1_new, w1_o2_new, b1_o_new, b2_o_new\n",
    "    w1_h1, w1_h2, w2_h1, w2_h2 = w1_h1_new, w1_h2_new, w2_h1_new, w2_h2_new\n",
    "    b1_h, b2_h = b1_h_new, b2_h_new\n",
    "\n",
    "    # Check if the error has reached the target threshold\n",
    "    if total_error < target_error_threshold:\n",
    "        break\n",
    "\n",
    "# Print the results\n",
    "print(\"Forward Pass (Iteration 1):\")\n",
    "print(\"a1_h =\", a1_h)\n",
    "print(\"a2_h =\", a2_h)\n",
    "print(\"a1_o =\", a1_o)\n",
    "print(\"a2_o =\", a2_o)\n",
    "\n",
    "print(\"\\nTotal Error after Backpropagation (Iteration 1):\", total_error)\n",
    "\n",
    "# Print the number of iterations and the minimum error achieved\n",
    "print(\"\\nNumber of Iterations:\", iteration + 1)\n",
    "print(\"Minimum Error:\", total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass (Iteration 1):\n",
      "a1_h = 0.7276911554702422\n",
      "a2_h = 0.6629256876062106\n",
      "a1_o = 0.042189118601334806\n",
      "a2_o = 0.9590126924110401\n",
      "\n",
      "Total Error after Backpropagation (Iteration 1): 0.0009981762939718034\n",
      "\n",
      "Number of Iterations: 500\n",
      "Minimum Error: 0.0009981762939718034\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Given Details\n",
    "x1 = 0.05\n",
    "x2 = 0.10\n",
    "b1_h = 0.35\n",
    "b2_h = 0.35\n",
    "b1_o = 0.60\n",
    "b2_o = 0.60\n",
    "w1_h1 = 0.15\n",
    "w1_h2 = 0.20\n",
    "w2_h1 = 0.25\n",
    "w2_h2 = 0.30\n",
    "w1_o1 = 0.40\n",
    "w1_o2 = 0.45\n",
    "w2_o1 = 0.50\n",
    "w2_o2 = 0.55\n",
    "t1_o = 0.01\n",
    "t2_o = 0.99\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Target Error Threshold\n",
    "target_error_threshold = 0.001\n",
    "\n",
    "# Maximum Number of Iterations\n",
    "max_iterations = 10000\n",
    "\n",
    "# Initialize weights and biases differently\n",
    "np.random.seed(42)  # For reproducibility\n",
    "w1_h1 = np.random.rand()\n",
    "w1_h2 = np.random.rand()\n",
    "w2_h1 = np.random.rand()\n",
    "w2_h2 = np.random.rand()\n",
    "w1_o1 = np.random.rand()\n",
    "w1_o2 = np.random.rand()\n",
    "w2_o1 = np.random.rand()\n",
    "w2_o2 = np.random.rand()\n",
    "\n",
    "# Training loop\n",
    "for iteration in range(max_iterations):\n",
    "    # Forward Pass\n",
    "    z1_h = (x1 * w1_h1) + (x2 * w2_h1) + b1_h\n",
    "    z2_h = (x1 * w1_h2) + (x2 * w2_h2) + b2_h\n",
    "    a1_h = sigmoid(z1_h)\n",
    "    a2_h = sigmoid(z2_h)\n",
    "\n",
    "    z1_o = (a1_h * w1_o1) + (a2_h * w2_o1) + b1_o\n",
    "    z2_o = (a1_h * w1_o2) + (a2_h * w2_o2) + b2_o\n",
    "    a1_o = sigmoid(z1_o)\n",
    "    a2_o = sigmoid(z2_o)\n",
    "\n",
    "    # Calculate Error\n",
    "    E1_o = 0.5 * (t1_o - a1_o)**2\n",
    "    E2_o = 0.5 * (t2_o - a2_o)**2\n",
    "    total_error = E1_o + E2_o\n",
    "\n",
    "    # Backward Pass\n",
    "    delta1_o = (a1_o - t1_o) * a1_o * (1 - a1_o)\n",
    "    delta2_o = (a2_o - t2_o) * a2_o * (1 - a2_o)\n",
    "\n",
    "    delta1_h = ((delta1_o * w1_o1) + (delta2_o * w1_o2)) * a1_h * (1 - a1_h)\n",
    "    delta2_h = ((delta1_o * w2_o1) + (delta2_o * w2_o2)) * a2_h * (1 - a2_h)\n",
    "\n",
    "    # Weight Updates\n",
    "    w1_o1_new = w1_o1 - (learning_rate * delta1_o * a1_h)\n",
    "    w1_o2_new = w1_o2 - (learning_rate * delta2_o * a1_h)\n",
    "    b1_o_new = b1_o - (learning_rate * delta1_o)\n",
    "    b2_o_new = b2_o - (learning_rate * delta2_o)\n",
    "\n",
    "    w1_h1_new = w1_h1 - (learning_rate * delta1_h * x1)\n",
    "    w1_h2_new = w1_h2 - (learning_rate * delta2_h * x1)\n",
    "    w2_h1_new = w2_h1 - (learning_rate * delta1_h * x2)\n",
    "    w2_h2_new = w2_h2 - (learning_rate * delta2_h * x2)\n",
    "    b1_h_new = b1_h - (learning_rate * delta1_h)\n",
    "    b2_h_new = b2_h - (learning_rate * delta2_h)\n",
    "\n",
    "    # Update weights and biases for the next iteration\n",
    "    w1_o1, w1_o2, b1_o, b2_o = w1_o1_new, w1_o2_new, b1_o_new, b2_o_new\n",
    "    w1_h1, w1_h2, w2_h1, w2_h2 = w1_h1_new, w1_h2_new, w2_h1_new, w2_h2_new\n",
    "    b1_h, b2_h = b1_h_new, b2_h_new\n",
    "\n",
    "    # Check if the error has reached the target threshold\n",
    "    if total_error < target_error_threshold:\n",
    "        break\n",
    "\n",
    "# Print the results\n",
    "print(\"Forward Pass (Iteration 1):\")\n",
    "print(\"a1_h =\", a1_h)\n",
    "print(\"a2_h =\", a2_h)\n",
    "print(\"a1_o =\", a1_o)\n",
    "print(\"a2_o =\", a2_o)\n",
    "\n",
    "print(\"\\nTotal Error after Backpropagation (Iteration 1):\", total_error)\n",
    "\n",
    "# Print the number of iterations and the minimum error achieved\n",
    "print(\"\\nNumber of Iterations:\", iteration + 1)\n",
    "print(\"Minimum Error:\", total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass (Iteration 1):\n",
      "a1_h = 0.7276911554702422\n",
      "a2_h = 0.6629256876062106\n",
      "a1_o = 0.042189118601334806\n",
      "a2_o = 0.9590126924110401\n",
      "\n",
      "Total Error after Backpropagation (Iteration 1): 0.0009981762939718034\n",
      "\n",
      "Number of Iterations: 500\n",
      "Minimum Error: 0.0009981762939718034\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Given Details\n",
    "x1 = 0.05\n",
    "x2 = 0.10\n",
    "b1_h = 0.35\n",
    "b2_h = 0.35\n",
    "b1_o = 0.60\n",
    "b2_o = 0.60\n",
    "w1_h1 = 0.15\n",
    "w1_h2 = 0.20\n",
    "w2_h1 = 0.25\n",
    "w2_h2 = 0.30\n",
    "w1_o1 = 0.40\n",
    "w1_o2 = 0.45\n",
    "w2_o1 = 0.50\n",
    "w2_o2 = 0.55\n",
    "t1_o = 0.01\n",
    "t2_o = 0.99\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Target Error Threshold\n",
    "target_error_threshold = 0.001\n",
    "\n",
    "# Maximum Number of Iterations\n",
    "max_iterations = 10000\n",
    "\n",
    "# Initialize weights and biases with random values\n",
    "np.random.seed(42)  # For reproducibility\n",
    "w1_h1 = np.random.rand()\n",
    "w1_h2 = np.random.rand()\n",
    "w2_h1 = np.random.rand()\n",
    "w2_h2 = np.random.rand()\n",
    "w1_o1 = np.random.rand()\n",
    "w1_o2 = np.random.rand()\n",
    "w2_o1 = np.random.rand()\n",
    "w2_o2 = np.random.rand()\n",
    "\n",
    "# Training loop\n",
    "for iteration in range(max_iterations):\n",
    "    # Forward Pass\n",
    "    z1_h = (x1 * w1_h1) + (x2 * w2_h1) + b1_h\n",
    "    z2_h = (x1 * w1_h2) + (x2 * w2_h2) + b2_h\n",
    "    a1_h = sigmoid(z1_h)\n",
    "    a2_h = sigmoid(z2_h)\n",
    "\n",
    "    z1_o = (a1_h * w1_o1) + (a2_h * w2_o1) + b1_o\n",
    "    z2_o = (a1_h * w1_o2) + (a2_h * w2_o2) + b2_o\n",
    "    a1_o = sigmoid(z1_o)\n",
    "    a2_o = sigmoid(z2_o)\n",
    "\n",
    "    # Calculate Error\n",
    "    E1_o = 0.5 * (t1_o - a1_o)**2\n",
    "    E2_o = 0.5 * (t2_o - a2_o)**2\n",
    "    total_error = E1_o + E2_o\n",
    "\n",
    "    # Backward Pass\n",
    "    delta1_o = (a1_o - t1_o) * a1_o * (1 - a1_o)\n",
    "    delta2_o = (a2_o - t2_o) * a2_o * (1 - a2_o)\n",
    "\n",
    "    delta1_h = ((delta1_o * w1_o1) + (delta2_o * w1_o2)) * a1_h * (1 - a1_h)\n",
    "    delta2_h = ((delta1_o * w2_o1) + (delta2_o * w2_o2)) * a2_h * (1 - a2_h)\n",
    "\n",
    "    # Weight Updates\n",
    "    w1_o1_new = w1_o1 - (learning_rate * delta1_o * a1_h)\n",
    "    w1_o2_new = w1_o2 - (learning_rate * delta2_o * a1_h)\n",
    "    b1_o_new = b1_o - (learning_rate * delta1_o)\n",
    "    b2_o_new = b2_o - (learning_rate * delta2_o)\n",
    "\n",
    "    w1_h1_new = w1_h1 - (learning_rate * delta1_h * x1)\n",
    "    w1_h2_new = w1_h2 - (learning_rate * delta2_h * x1)\n",
    "    w2_h1_new = w2_h1 - (learning_rate * delta1_h * x2)\n",
    "    w2_h2_new = w2_h2 - (learning_rate * delta2_h * x2)\n",
    "    b1_h_new = b1_h - (learning_rate * delta1_h)\n",
    "    b2_h_new = b2_h - (learning_rate * delta2_h)\n",
    "\n",
    "    # Update weights and biases for the next iteration\n",
    "    w1_o1, w1_o2, b1_o, b2_o = w1_o1_new, w1_o2_new, b1_o_new, b2_o_new\n",
    "    w1_h1, w1_h2, w2_h1, w2_h2 = w1_h1_new, w1_h2_new, w2_h1_new, w2_h2_new\n",
    "    b1_h, b2_h = b1_h_new, b2_h_new\n",
    "\n",
    "    # Check if the error has reached the target threshold\n",
    "    if total_error < target_error_threshold:\n",
    "        break\n",
    "\n",
    "# Print the results\n",
    "print(\"Forward Pass (Iteration 1):\")\n",
    "print(\"a1_h =\", a1_h)\n",
    "print(\"a2_h =\", a2_h)\n",
    "print(\"a1_o =\", a1_o)\n",
    "print(\"a2_o =\", a2_o)\n",
    "\n",
    "print(\"\\nTotal Error after Backpropagation (Iteration 1):\", total_error)\n",
    "\n",
    "# Print the number of iterations and the minimum error achieved\n",
    "print(\"\\nNumber of Iterations:\", iteration + 1)\n",
    "print(\"Minimum Error:\", total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass (Iteration 1):\n",
      "a1_h = 0.6338606995289567\n",
      "a2_h = 0.6149562127058794\n",
      "a1_o = 0.041924785145345825\n",
      "a2_o = 0.9586916168608014\n",
      "\n",
      "Total Error after Backpropagation (Iteration 1): 0.000999703380683674\n",
      "\n",
      "Number of Iterations: 1933\n",
      "Minimum Error: 0.000999703380683674\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Given Details\n",
    "x1 = 0.05\n",
    "x2 = 0.10\n",
    "b1_h = 0.35\n",
    "b2_h = 0.35\n",
    "b1_o = 0.60\n",
    "b2_o = 0.60\n",
    "w1_h1 = 0.15\n",
    "w1_h2 = 0.20\n",
    "w2_h1 = 0.25\n",
    "w2_h2 = 0.30\n",
    "w1_o1 = 0.40\n",
    "w1_o2 = 0.45\n",
    "w2_o1 = 0.50\n",
    "w2_o2 = 0.55\n",
    "t1_o = 0.01\n",
    "t2_o = 0.99\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Target Error Threshold\n",
    "target_error_threshold = 0.001\n",
    "\n",
    "# Maximum Number of Iterations\n",
    "max_iterations = 10000\n",
    "\n",
    "# Initialize weights and biases randomly\n",
    "np.random.seed(42)  # For reproducibility\n",
    "w1_h1_new = np.random.rand()\n",
    "w1_h2_new = np.random.rand()\n",
    "w2_h1_new = np.random.rand()\n",
    "w2_h2_new = np.random.rand()\n",
    "w1_o1_new = np.random.rand()\n",
    "w1_o2_new = np.random.rand()\n",
    "w2_o1_new = np.random.rand()\n",
    "w2_o2_new = np.random.rand()\n",
    "\n",
    "# Training loop\n",
    "for iteration in range(max_iterations):\n",
    "    # Use updated weights and biases\n",
    "    w1_h1, w1_h2, w2_h1, w2_h2 = w1_h1_new, w1_h2_new, w2_h1_new, w2_h2_new\n",
    "    w1_o1, w1_o2, w2_o1, w2_o2 = w1_o1_new, w1_o2_new, w2_o1_new, w2_o2_new\n",
    "\n",
    "    # Forward Pass\n",
    "    z1_h = (x1 * w1_h1) + (x2 * w2_h1) + b1_h\n",
    "    z2_h = (x1 * w1_h2) + (x2 * w2_h2) + b2_h\n",
    "    a1_h = sigmoid(z1_h)\n",
    "    a2_h = sigmoid(z2_h)\n",
    "\n",
    "    z1_o = (a1_h * w1_o1) + (a2_h * w2_o1) + b1_o\n",
    "    z2_o = (a1_h * w1_o2) + (a2_h * w2_o2) + b2_o\n",
    "    a1_o = sigmoid(z1_o)\n",
    "    a2_o = sigmoid(z2_o)\n",
    "\n",
    "    # Calculate Error\n",
    "    E1_o = 0.5 * (t1_o - a1_o)**2\n",
    "    E2_o = 0.5 * (t2_o - a2_o)**2\n",
    "    total_error = E1_o + E2_o\n",
    "\n",
    "    # Backward Pass\n",
    "    delta1_o = (a1_o - t1_o) * a1_o * (1 - a1_o)\n",
    "    delta2_o = (a2_o - t2_o) * a2_o * (1 - a2_o)\n",
    "\n",
    "    delta1_h = ((delta1_o * w1_o1) + (delta2_o * w1_o2)) * a1_h * (1 - a1_h)\n",
    "    delta2_h = ((delta1_o * w2_o1) + (delta2_o * w2_o2)) * a2_h * (1 - a2_h)\n",
    "\n",
    "    # Store current weights and biases for updating\n",
    "    w1_o1_current, w1_o2_current, w2_o1_current, w2_o2_current = w1_o1, w1_o2, w2_o1, w2_o2\n",
    "    b1_o_current, b2_o_current = b1_o, b2_o\n",
    "\n",
    "    # Weight Updates (for the next iteration)\n",
    "    w1_o1_new = w1_o1 - (learning_rate * delta1_o * a1_h)\n",
    "    w1_o2_new = w1_o2 - (learning_rate * delta2_o * a1_h)\n",
    "    b1_o_new = b1_o - (learning_rate * delta1_o)\n",
    "    b2_o_new = b2_o - (learning_rate * delta2_o)\n",
    "\n",
    "    w1_h1_new = w1_h1 - (learning_rate * delta1_h * x1)\n",
    "    w1_h2_new = w1_h2 - (learning_rate * delta2_h * x1)\n",
    "    w2_h1_new = w2_h1 - (learning_rate * delta1_h * x2)\n",
    "    w2_h2_new = w2_h2 - (learning_rate * delta2_h * x2)\n",
    "    b1_h_new = b1_h - (learning_rate * delta1_h)\n",
    "    b2_h_new = b2_h - (learning_rate * delta2_h)\n",
    "\n",
    "    # Check if the error has reached the target threshold\n",
    "    if total_error < target_error_threshold:\n",
    "        break\n",
    "\n",
    "# Print the results\n",
    "print(\"Forward Pass (Iteration 1):\")\n",
    "print(\"a1_h =\", a1_h)\n",
    "print(\"a2_h =\", a2_h)\n",
    "print(\"a1_o =\", a1_o)\n",
    "print(\"a2_o =\", a2_o)\n",
    "\n",
    "print(\"\\nTotal Error after Backpropagation (Iteration 1):\", total_error)\n",
    "\n",
    "# Print the number of iterations and the minimum error achieved\n",
    "print(\"\\nNumber of Iterations:\", iteration + 1)\n",
    "print(\"Minimum Error:\", total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass (Iteration 1):\n",
      "a1_h = 0.6087179574825822\n",
      "a2_h = 0.6123975741078985\n",
      "a1_o = 0.6749241142054254\n",
      "a2_o = 0.7730125994682051\n",
      "\n",
      "Total Error after Backpropagation (Iteration 1): 0.2446038048207076\n",
      "\n",
      "Number of Iterations: 1\n",
      "Minimum Error: 0.2446038048207076\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Given Details\n",
    "x1 = 0.05\n",
    "x2 = 0.10\n",
    "b1_h = 0.35\n",
    "b2_h = 0.35\n",
    "b1_o = 0.60\n",
    "b2_o = 0.60\n",
    "w1_h1 = 0.15\n",
    "w1_h2 = 0.20\n",
    "w2_h1 = 0.25\n",
    "w2_h2 = 0.30\n",
    "w1_o1 = 0.40\n",
    "w1_o2 = 0.45\n",
    "w2_o1 = 0.50\n",
    "w2_o2 = 0.55\n",
    "t1_o = 0.01\n",
    "t2_o = 0.99\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Target Error Threshold\n",
    "target_error_threshold = 0.001\n",
    "\n",
    "# Maximum Number of Iterations\n",
    "max_iterations = 10000\n",
    "\n",
    "# Initialize weights and biases randomly\n",
    "np.random.seed(42)  # For reproducibility\n",
    "w1_h1_new = np.random.rand()\n",
    "w1_h2_new = np.random.rand()\n",
    "w2_h1_new = np.random.rand()\n",
    "w2_h2_new = np.random.rand()\n",
    "w1_o1_new = np.random.rand()\n",
    "w1_o2_new = np.random.rand()\n",
    "w2_o1_new = np.random.rand()\n",
    "w2_o2_new = np.random.rand()\n",
    "\n",
    "# Training loop\n",
    "for iteration in range(1):\n",
    "    # Use updated weights and biases\n",
    "    w1_h1, w1_h2, w2_h1, w2_h2 = w1_h1_new, w1_h2_new, w2_h1_new, w2_h2_new\n",
    "    w1_o1, w1_o2, w2_o1, w2_o2 = w1_o1_new, w1_o2_new, w2_o1_new, w2_o2_new\n",
    "\n",
    "    # Forward Pass\n",
    "    z1_h = (x1 * w1_h1) + (x2 * w2_h1) + b1_h\n",
    "    z2_h = (x1 * w1_h2) + (x2 * w2_h2) + b2_h\n",
    "    a1_h = sigmoid(z1_h)\n",
    "    a2_h = sigmoid(z2_h)\n",
    "\n",
    "    z1_o = (a1_h * w1_o1) + (a2_h * w2_o1) + b1_o\n",
    "    z2_o = (a1_h * w1_o2) + (a2_h * w2_o2) + b2_o\n",
    "    a1_o = sigmoid(z1_o)\n",
    "    a2_o = sigmoid(z2_o)\n",
    "\n",
    "    # Calculate Error\n",
    "    E1_o = 0.5 * (t1_o - a1_o)**2\n",
    "    E2_o = 0.5 * (t2_o - a2_o)**2\n",
    "    total_error = E1_o + E2_o\n",
    "\n",
    "    # Backward Pass\n",
    "    delta1_o = (a1_o - t1_o) * a1_o * (1 - a1_o)\n",
    "    delta2_o = (a2_o - t2_o) * a2_o * (1 - a2_o)\n",
    "\n",
    "    delta1_h = ((delta1_o * w1_o1) + (delta2_o * w1_o2)) * a1_h * (1 - a1_h)\n",
    "    delta2_h = ((delta1_o * w2_o1) + (delta2_o * w2_o2)) * a2_h * (1 - a2_h)\n",
    "\n",
    "    # Store current weights and biases for updating\n",
    "    w1_o1_current, w1_o2_current, w2_o1_current, w2_o2_current = w1_o1, w1_o2, w2_o1, w2_o2\n",
    "    b1_o_current, b2_o_current = b1_o, b2_o\n",
    "\n",
    "    # Weight Updates (for the next iteration)\n",
    "    w1_o1_new = w1_o1 - (learning_rate * delta1_o * a1_h)\n",
    "    w1_o2_new = w1_o2 - (learning_rate * delta2_o * a1_h)\n",
    "    b1_o_new = b1_o - (learning_rate * delta1_o)\n",
    "    b2_o_new = b2_o - (learning_rate * delta2_o)\n",
    "\n",
    "    w1_h1_new = w1_h1 - (learning_rate * delta1_h * x1)\n",
    "    w1_h2_new = w1_h2 - (learning_rate * delta2_h * x1)\n",
    "    w2_h1_new = w2_h1 - (learning_rate * delta1_h * x2)\n",
    "    w2_h2_new = w2_h2 - (learning_rate * delta2_h * x2)\n",
    "    b1_h_new = b1_h - (learning_rate * delta1_h)\n",
    "    b2_h_new = b2_h - (learning_rate * delta2_h)\n",
    "\n",
    "    # Check if the error has reached the target threshold\n",
    "    if total_error < target_error_threshold:\n",
    "        break\n",
    "\n",
    "# Print the results\n",
    "print(\"Forward Pass (Iteration 1):\")\n",
    "print(\"a1_h =\", a1_h)\n",
    "print(\"a2_h =\", a2_h)\n",
    "print(\"a1_o =\", a1_o)\n",
    "print(\"a2_o =\", a2_o)\n",
    "\n",
    "print(\"\\nTotal Error after Backpropagation (Iteration 1):\", total_error)\n",
    "\n",
    "# Print the number of iterations and the minimum error achieved\n",
    "print(\"\\nNumber of Iterations:\", iteration + 1)\n",
    "print(\"Minimum Error:\", total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass (Iteration 1):\n",
      "a1_h = 0.6087179574825822\n",
      "a2_h = 0.6123975741078985\n",
      "a1_o = 0.6749241142054254\n",
      "a2_o = 0.7730125994682051\n",
      "\n",
      "Total Error after Backpropagation (Iteration 1): 0.2446038048207076\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Given Details\n",
    "x1 = 0.05\n",
    "x2 = 0.10\n",
    "b1_h = 0.35\n",
    "b2_h = 0.35\n",
    "b1_o = 0.60\n",
    "b2_o = 0.60\n",
    "w1_h1 = 0.15\n",
    "w1_h2 = 0.20\n",
    "w2_h1 = 0.25\n",
    "w2_h2 = 0.30\n",
    "w1_o1 = 0.40\n",
    "w1_o2 = 0.45\n",
    "w2_o1 = 0.50\n",
    "w2_o2 = 0.55\n",
    "t1_o = 0.01\n",
    "t2_o = 0.99\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Target Error Threshold\n",
    "target_error_threshold = 0.001\n",
    "\n",
    "# Maximum Number of Iterations\n",
    "max_iterations = 10000\n",
    "\n",
    "# Initialize weights and biases randomly\n",
    "np.random.seed(42)  # For reproducibility\n",
    "w1_h1_new = np.random.rand()\n",
    "w1_h2_new = np.random.rand()\n",
    "w2_h1_new = np.random.rand()\n",
    "w2_h2_new = np.random.rand()\n",
    "w1_o1_new = np.random.rand()\n",
    "w1_o2_new = np.random.rand()\n",
    "w2_o1_new = np.random.rand()\n",
    "w2_o2_new = np.random.rand()\n",
    "\n",
    "# Training loop\n",
    "for iteration in range(1):\n",
    "    # Use updated weights and biases\n",
    "    w1_h1, w1_h2, w2_h1, w2_h2 = w1_h1_new, w1_h2_new, w2_h1_new, w2_h2_new\n",
    "    w1_o1, w1_o2, w2_o1, w2_o2 = w1_o1_new, w1_o2_new, w2_o1_new, w2_o2_new\n",
    "\n",
    "    # Forward Pass\n",
    "    z1_h = (x1 * w1_h1) + (x2 * w2_h1) + b1_h\n",
    "    z2_h = (x1 * w1_h2) + (x2 * w2_h2) + b2_h\n",
    "    a1_h = sigmoid(z1_h)\n",
    "    a2_h = sigmoid(z2_h)\n",
    "\n",
    "    z1_o = (a1_h * w1_o1) + (a2_h * w2_o1) + b1_o\n",
    "    z2_o = (a1_h * w1_o2) + (a2_h * w2_o2) + b2_o\n",
    "    a1_o = sigmoid(z1_o)\n",
    "    a2_o = sigmoid(z2_o)\n",
    "\n",
    "    # Calculate Error\n",
    "    E1_o = 0.5 * (t1_o - a1_o)**2\n",
    "    E2_o = 0.5 * (t2_o - a2_o)**2\n",
    "    total_error = E1_o + E2_o\n",
    "\n",
    "    # Backward Pass\n",
    "    delta1_o = (a1_o - t1_o) * a1_o * (1 - a1_o)\n",
    "    delta2_o = (a2_o - t2_o) * a2_o * (1 - a2_o)\n",
    "\n",
    "    delta1_h = ((delta1_o * w1_o1) + (delta2_o * w1_o2)) * a1_h * (1 - a1_h)\n",
    "    delta2_h = ((delta1_o * w2_o1) + (delta2_o * w2_o2)) * a2_h * (1 - a2_h)\n",
    "\n",
    "    # Store current weights and biases for updating\n",
    "    w1_o1_current, w1_o2_current, w2_o1_current, w2_o2_current = w1_o1, w1_o2, w2_o1, w2_o2\n",
    "    b1_o_current, b2_o_current = b1_o, b2_o\n",
    "\n",
    "    # Weight Updates (for the next iteration)\n",
    "    w1_o1_new = w1_o1 - (learning_rate * delta1_o * a1_h)\n",
    "    w1_o2_new = w1_o2 - (learning_rate * delta2_o * a1_h)\n",
    "    b1_o_new = b1_o - (learning_rate * delta1_o)\n",
    "    b2_o_new = b2_o - (learning_rate * delta2_o)\n",
    "\n",
    "    w1_h1_new = w1_h1 - (learning_rate * delta1_h * x1)\n",
    "    w1_h2_new = w1_h2 - (learning_rate * delta2_h * x1)\n",
    "    w2_h1_new = w2_h1 - (learning_rate * delta1_h * x2)\n",
    "    w2_h2_new = w2_h2 - (learning_rate * delta2_h * x2)\n",
    "    b1_h_new = b1_h - (learning_rate * delta1_h)\n",
    "    b2_h_new = b2_h - (learning_rate * delta2_h)\n",
    "\n",
    "    # Check if the error has reached the target threshold\n",
    "    if total_error < target_error_threshold:\n",
    "        break\n",
    "\n",
    "# Print the results\n",
    "print(\"Forward Pass (Iteration 1):\")\n",
    "print(\"a1_h =\", a1_h)\n",
    "print(\"a2_h =\", a2_h)\n",
    "print(\"a1_o =\", a1_o)\n",
    "print(\"a2_o =\", a2_o)\n",
    "\n",
    "print(\"\\nTotal Error after Backpropagation (Iteration 1):\", total_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Iterations: 1933\n",
      "Minimum Error: 0.000999703380683674\n"
     ]
    }
   ],
   "source": [
    "max_iterations =10000\n",
    "\n",
    "# Initialize weights and biases randomly\n",
    "np.random.seed(42)  # For reproducibility\n",
    "w1_h1_new = np.random.rand()\n",
    "w1_h2_new = np.random.rand()\n",
    "w2_h1_new = np.random.rand()\n",
    "w2_h2_new = np.random.rand()\n",
    "w1_o1_new = np.random.rand()\n",
    "w1_o2_new = np.random.rand()\n",
    "w2_o1_new = np.random.rand()\n",
    "w2_o2_new = np.random.rand()\n",
    "\n",
    "# Training loop\n",
    "for iteration in range(max_iterations):\n",
    "    # Use updated weights and biases\n",
    "    w1_h1, w1_h2, w2_h1, w2_h2 = w1_h1_new, w1_h2_new, w2_h1_new, w2_h2_new\n",
    "    w1_o1, w1_o2, w2_o1, w2_o2 = w1_o1_new, w1_o2_new, w2_o1_new, w2_o2_new\n",
    "\n",
    "    # Forward Pass\n",
    "    z1_h = (x1 * w1_h1) + (x2 * w2_h1) + b1_h\n",
    "    z2_h = (x1 * w1_h2) + (x2 * w2_h2) + b2_h\n",
    "    a1_h = sigmoid(z1_h)\n",
    "    a2_h = sigmoid(z2_h)\n",
    "\n",
    "    z1_o = (a1_h * w1_o1) + (a2_h * w2_o1) + b1_o\n",
    "    z2_o = (a1_h * w1_o2) + (a2_h * w2_o2) + b2_o\n",
    "    a1_o = sigmoid(z1_o)\n",
    "    a2_o = sigmoid(z2_o)\n",
    "\n",
    "    # Calculate Error\n",
    "    E1_o = 0.5 * (t1_o - a1_o)**2\n",
    "    E2_o = 0.5 * (t2_o - a2_o)**2\n",
    "    total_error = E1_o + E2_o\n",
    "\n",
    "    # Backward Pass\n",
    "    delta1_o = (a1_o - t1_o) * a1_o * (1 - a1_o)\n",
    "    delta2_o = (a2_o - t2_o) * a2_o * (1 - a2_o)\n",
    "\n",
    "    delta1_h = ((delta1_o * w1_o1) + (delta2_o * w1_o2)) * a1_h * (1 - a1_h)\n",
    "    delta2_h = ((delta1_o * w2_o1) + (delta2_o * w2_o2)) * a2_h * (1 - a2_h)\n",
    "\n",
    "    # Store current weights and biases for updating\n",
    "    w1_o1_current, w1_o2_current, w2_o1_current, w2_o2_current = w1_o1, w1_o2, w2_o1, w2_o2\n",
    "    b1_o_current, b2_o_current = b1_o, b2_o\n",
    "\n",
    "    # Weight Updates (for the next iteration)\n",
    "    w1_o1_new = w1_o1 - (learning_rate * delta1_o * a1_h)\n",
    "    w1_o2_new = w1_o2 - (learning_rate * delta2_o * a1_h)\n",
    "    b1_o_new = b1_o - (learning_rate * delta1_o)\n",
    "    b2_o_new = b2_o - (learning_rate * delta2_o)\n",
    "\n",
    "    w1_h1_new = w1_h1 - (learning_rate * delta1_h * x1)\n",
    "    w1_h2_new = w1_h2 - (learning_rate * delta2_h * x1)\n",
    "    w2_h1_new = w2_h1 - (learning_rate * delta1_h * x2)\n",
    "    w2_h2_new = w2_h2 - (learning_rate * delta2_h * x2)\n",
    "    b1_h_new = b1_h - (learning_rate * delta1_h)\n",
    "    b2_h_new = b2_h - (learning_rate * delta2_h)\n",
    "\n",
    "    # Check if the error has reached the target threshold\n",
    "    if total_error < target_error_threshold:\n",
    "        break\n",
    "        \n",
    "    # Print the number of iterations and the minimum error achieved\n",
    "print(\"\\nNumber of Iterations:\", iteration + 1)\n",
    "print(\"Minimum Error:\", total_error)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Table:\n",
      "Activation Function | Iterations to Reach Target | Minimum Error\n",
      "Sigmoid            | 1933                        | 0.000999703380683674\n",
      "ReLU               | 10000                       | 0.2501       \n",
      "Tanh               | 1095                        | 0.0009992629342561662\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define activation functions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "# Given Details\n",
    "# ... (same as before)\n",
    "\n",
    "# List of activation functions to test\n",
    "activation_functions = [sigmoid, relu, tanh]\n",
    "activation_names = ['Sigmoid', 'ReLU', 'Tanh']\n",
    "\n",
    "# Initialize results table\n",
    "results_table = []\n",
    "\n",
    "# Training loop for each activation function\n",
    "for activation_func, activation_name in zip(activation_functions, activation_names):\n",
    "    # Initialize weights and biases randomly\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    w1_h1_new = np.random.rand()\n",
    "    w1_h2_new = np.random.rand()\n",
    "    w2_h1_new = np.random.rand()\n",
    "    w2_h2_new = np.random.rand()\n",
    "    w1_o1_new = np.random.rand()\n",
    "    w1_o2_new = np.random.rand()\n",
    "    w2_o1_new = np.random.rand()\n",
    "    w2_o2_new = np.random.rand()\n",
    "\n",
    "    # Training loop\n",
    "    for iteration in range(max_iterations):\n",
    "        # Use updated weights and biases\n",
    "        w1_h1, w1_h2, w2_h1, w2_h2 = w1_h1_new, w1_h2_new, w2_h1_new, w2_h2_new\n",
    "        w1_o1, w1_o2, w2_o1, w2_o2 = w1_o1_new, w1_o2_new, w2_o1_new, w2_o2_new\n",
    "\n",
    "        # Forward Pass\n",
    "        z1_h = (x1 * w1_h1) + (x2 * w2_h1) + b1_h\n",
    "        z2_h = (x1 * w1_h2) + (x2 * w2_h2) + b2_h\n",
    "        a1_h = activation_func(z1_h)\n",
    "        a2_h = activation_func(z2_h)\n",
    "\n",
    "        z1_o = (a1_h * w1_o1) + (a2_h * w2_o1) + b1_o\n",
    "        z2_o = (a1_h * w1_o2) + (a2_h * w2_o2) + b2_o\n",
    "        a1_o = activation_func(z1_o)\n",
    "        a2_o = activation_func(z2_o)\n",
    "\n",
    "        # Calculate Error\n",
    "        E1_o = 0.5 * (t1_o - a1_o)**2\n",
    "        E2_o = 0.5 * (t2_o - a2_o)**2\n",
    "        total_error = E1_o + E2_o\n",
    "\n",
    "        # Backward Pass\n",
    "        delta1_o = (a1_o - t1_o) * a1_o * (1 - a1_o)\n",
    "        delta2_o = (a2_o - t2_o) * a2_o * (1 - a2_o)\n",
    "\n",
    "        delta1_h = ((delta1_o * w1_o1) + (delta2_o * w1_o2)) * a1_h * (1 - a1_h)\n",
    "        delta2_h = ((delta1_o * w2_o1) + (delta2_o * w2_o2)) * a2_h * (1 - a2_h)\n",
    "\n",
    "        # Store current weights and biases for updating\n",
    "        w1_o1_current, w1_o2_current, w2_o1_current, w2_o2_current = w1_o1, w1_o2, w2_o1, w2_o2\n",
    "        b1_o_current, b2_o_current = b1_o, b2_o\n",
    "\n",
    "        # Weight Updates (for the next iteration)\n",
    "        w1_o1_new = w1_o1 - (learning_rate * delta1_o * a1_h)\n",
    "        w1_o2_new = w1_o2 - (learning_rate * delta2_o * a1_h)\n",
    "        b1_o_new = b1_o - (learning_rate * delta1_o)\n",
    "        b2_o_new = b2_o - (learning_rate * delta2_o)\n",
    "\n",
    "        w1_h1_new = w1_h1 - (learning_rate * delta1_h * x1)\n",
    "        w1_h2_new = w1_h2 - (learning_rate * delta2_h * x1)\n",
    "        w2_h1_new = w2_h1 - (learning_rate * delta1_h * x2)\n",
    "        w2_h2_new = w2_h2 - (learning_rate * delta2_h * x2)\n",
    "        b1_h_new = b1_h - (learning_rate * delta1_h)\n",
    "        b2_h_new = b2_h - (learning_rate * delta2_h)\n",
    "\n",
    "        # Check if the error has reached the target threshold\n",
    "        if total_error < target_error_threshold:\n",
    "            break\n",
    "\n",
    "    # Append results to the table\n",
    "    results_table.append([activation_name, iteration + 1, total_error])\n",
    "\n",
    "# Print results table\n",
    "print(\"\\nResults Table:\")\n",
    "print(\"Activation Function | Iterations to Reach Target | Minimum Error\")\n",
    "for row in results_table:\n",
    "    print(f\"{row[0]:<18} | {row[1]:<27} | {row[2]:<13}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
